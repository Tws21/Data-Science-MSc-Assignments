{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fda8dac",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment\n",
    "## Setup Libraries and Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ce8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries?\n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install aif360\n",
    "!pip install sklearn\n",
    "!pip install dataframe-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ad8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from aif360.datasets import AdultDataset\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_german\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.sklearn.metrics import make_scorer\n",
    "from aif360.sklearn.metrics import equal_opportunity_difference\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from sklearn.preprocessing import StandardScaler  #MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import dataframe_image as dfi\n",
    "\n",
    "# Set numpy random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e238cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any functions and classes to be used\n",
    "\n",
    "# K-fold cross validation for TPR Difference\n",
    "def ManualKFold(data,method,unprivileged_groups,privileged_groups,**params):\n",
    "    tpr_diffs=[]\n",
    "    # Always reset seed as sci-kit learn uses numpy random seed and we want to validate results throughout\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # 5-fold validation for loop\n",
    "    for i in range(5):\n",
    "        # use aif360 subset method to create train and test data, using indices for distinct fifths of samples\n",
    "        train_i = data.subset([j for j in range(0,int(np.floor(i*data.features.shape[0]/5)))] +\n",
    "                              [j for j in range(int(np.floor((i+1)*data.features.shape[0]/5)), \n",
    "                                                data.features.shape[0]-1)])\n",
    "        test_i = data.subset([j for j in range(int(np.floor(i*data.features.shape[0]/5)),\n",
    "                                               int(np.floor((i+1)*data.features.shape[0]/5)))])\n",
    "        # scale to min/max and get targets\n",
    "        X_train_i = scale_orig.fit_transform(train_i.features)\n",
    "        y_train_i = train_i.labels.ravel()\n",
    "        # scale to min/max and get targets    \n",
    "        X_test_i = scale_orig.transform(test_i.features)\n",
    "        y_test_i = test_i.labels.ravel()\n",
    "            \n",
    "        if method == 'LogReg':\n",
    "            # Logistic regression defined here\n",
    "            learner = LogisticRegression(**params,random_state=1)\n",
    "        elif method == 'RForest':\n",
    "            # Randomn Forest defined here\n",
    "            learner = RandomForestClassifier(**params,random_state=1)\n",
    "        else:\n",
    "            # Other methods may be coded here\n",
    "            raise ValueError('Invalid classification method')\n",
    "        \n",
    "        # Fit to chosen classification method and predict on test set\n",
    "        learner.fit(X_train_i,y_train_i,sample_weight=train_i.instance_weights)\n",
    "        predictions = learner.predict(X_test_i)\n",
    "        \n",
    "        # Compute TPR Difference using AIF360 metrics\n",
    "        test_i_pred = test_i.copy()\n",
    "        test_i_pred.labels = predictions\n",
    "        metric = ClassificationMetric(test_i, test_i_pred, unprivileged_groups=unprivileged_groups, \n",
    "                                      privileged_groups=privileged_groups)\n",
    "            \n",
    "        tpr_diff = metric.equal_opportunity_difference()\n",
    "        tpr_diffs.append(tpr_diff)\n",
    "    # return all values    \n",
    "    return tpr_diffs\n",
    "\n",
    "# Grid search for TPR difference\n",
    "def GridSearchTPR(data,method,unprivileged_groups,privileged_groups,param_values_dict):\n",
    "    # Find best params for TPR difference fairness\n",
    "    param_grid_dicts = ParameterGrid(param_values_dict)\n",
    "    \n",
    "    print(\"Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_params = {}\n",
    "    tpr_diff_means = []\n",
    "    # Loop through each parameter combination\n",
    "    for params in param_grid_dicts:\n",
    "        # Perform K-Fold validation for chosen parameters\n",
    "        tpr_diffs = ManualKFold(data,method,unprivileged_groups,privileged_groups,**params)\n",
    "        tpr_diff_means.append(np.mean(tpr_diffs))\n",
    "        \n",
    "        # update best score and parameters if current score is greater than max score\n",
    "        if np.mean(tpr_diffs) > best_score:\n",
    "            best_params = params\n",
    "            best_score = np.mean(tpr_diffs)\n",
    "        \n",
    "    print(\"Best: %f using %s\" % (best_score, best_params))\n",
    "    # Output best score, best parameters and all scores and parameters in lists\n",
    "    return (best_score, best_params, tpr_diff_means, param_grid_dicts)\n",
    "\n",
    "# Grid search for accuracy\n",
    "def GridSearchAccuracy(model,grid,X,y,instance_weights):\n",
    "    # reset random seed again\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    weighted_grid = grid.copy()\n",
    "    # add instance weights to parameters for GridSearchCV\n",
    "    weighted_grid['sample_weights'] = instance_weights\n",
    "    # define folds\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "    # define grid search for best accuracy\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=kf, scoring='accuracy',error_score=0)\n",
    "    # fit grid to data\n",
    "    grid_result = grid_search.fit(X, y)\n",
    "    \n",
    "    # summarize results\n",
    "    print(\"Accuracy\")\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    \n",
    "    # return best score, best parameters and all grid search results\n",
    "    return (grid_result.best_score_, grid_result.best_params_, grid_result.cv_results_)\n",
    "\n",
    "# Get the accuracy and fairness for the most accurate and fairest parameters\n",
    "def GetAccAndFairnessForBestParams(acc_params,fair_params,X_train,y_train,X_test,y_test,test,\n",
    "                                   unprivileged_groups,privileged_groups,method,instance_weights):\n",
    "    # reset random seed again\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    if method == 'LogReg':\n",
    "        # most accurate parameters fit for Logistic Regression\n",
    "        acc_fit = LogisticRegression(C=acc_params['C'],penalty=acc_params['penalty'],\n",
    "                                     solver=acc_params['solver']).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "        # fairest parameters fit for Logistic Regression\n",
    "        fair_fit = LogisticRegression(C=fair_params['C'],penalty=fair_params['penalty'],\n",
    "                              solver=fair_params['solver']).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "    elif method == 'RForest':\n",
    "        # most accurate parameters fit for Random Forest\n",
    "        acc_fit = RandomForestClassifier(bootstrap=True,max_depth=acc_params['max_depth'],\n",
    "                                         max_features=acc_params['max_features'],min_samples_leaf=1,\n",
    "                                         min_samples_split=2,n_estimators=acc_params['n_estimators'],\n",
    "                                         random_state=1).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "        # most accurate parameters fit for Random Forest\n",
    "        fair_fit = RandomForestClassifier(bootstrap=True,max_depth=fair_params['max_depth'],\n",
    "                                         max_features=fair_params['max_features'],min_samples_leaf=1,\n",
    "                                         min_samples_split=2,n_estimators=fair_params['n_estimators'],\n",
    "                                         random_state=1).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "    else:\n",
    "        raise ValueError('Invalid classification method')\n",
    "    \n",
    "    # Predict on test set using chosen fit\n",
    "    acc_predict = acc_fit.predict(X_test)\n",
    "    fair_predict = fair_fit.predict(X_test)\n",
    "    \n",
    "    # calculate TPR difference for most accurate parameters\n",
    "    acc_test_pred = test.copy()\n",
    "    acc_test_pred.labels = acc_predict\n",
    "    acc_metric = ClassificationMetric(test,acc_test_pred,unprivileged_groups=unprivileged_groups,\n",
    "                                      privileged_groups=privileged_groups)\n",
    "    acc_tpr_diff = acc_metric.equal_opportunity_difference()\n",
    "     \n",
    "    # calculate TPR difference for most fairest parameters    \n",
    "    fair_test_pred = test.copy()\n",
    "    fair_test_pred.labels = fair_predict\n",
    "    fair_metric = ClassificationMetric(test,fair_test_pred,unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups_ad)\n",
    "    fair_tpr_diff = fair_metric.equal_opportunity_difference()\n",
    "    \n",
    "    # calculate accuracy for both parameters\n",
    "    acc_acc = sum(acc_predict==y_test)/len(y_test)\n",
    "    fair_acc = sum(fair_predict==y_test)/len(y_test)\n",
    "        \n",
    "    print(acc_params, \"Accuracy\", acc_acc)\n",
    "    print(fair_params, \"Accuracy\", fair_acc)\n",
    "    print(acc_params, \"Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\", \n",
    "          acc_tpr_diff)\n",
    "    print(fair_params, \"Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\", \n",
    "          fair_tpr_diff)\n",
    "    # return the accuracy then fairness respectively, for the most accurate parameters then the fairest ones\n",
    "    return (acc_acc, fair_acc, acc_tpr_diff, fair_tpr_diff)\n",
    "\n",
    "# Get accuracy for chosen parameters\n",
    "def GetAccuracy(params,X_train,y_train,X_test,y_test,test,unprivileged_groups,privileged_groups,method,\n",
    "                instance_weights):\n",
    "    # reset seed again\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # choose fit method depending on user input\n",
    "    if method == 'LogReg':\n",
    "        fit = LogisticRegression(C=params['C'],penalty=params['penalty'],\n",
    "                                 solver=params['solver']).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "    elif method == 'RForest':\n",
    "        fit = RandomForestClassifier(bootstrap=True,max_depth=params['max_depth'],\n",
    "                                         max_features=params['max_features'],min_samples_leaf=1,\n",
    "                                         min_samples_split=2,n_estimators=params['n_estimators'],\n",
    "                                         random_state=1).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "    else:\n",
    "        raise ValueError('Invalid classification method')\n",
    "    \n",
    "    # make prediction on test set\n",
    "    predict = fit.predict(X_test)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    test_pred = test.copy()\n",
    "    test_pred.labels = predict\n",
    "    acc = sum(predict==y_test)/len(y_test)\n",
    "          \n",
    "    return acc\n",
    "\n",
    "# Get fairness (TPR difference) for chosen parameters\n",
    "def GetFairness(params,X_train,y_train,X_test,y_test,test,unprivileged_groups,privileged_groups,method,\n",
    "                instance_weights):\n",
    "    # reset seed again\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # choose fit method depending on user input\n",
    "    if method == 'LogReg':\n",
    "        fit = LogisticRegression(C=params['C'],penalty=params['penalty'],\n",
    "                                 solver=params['solver']).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "    elif method == 'RForest':\n",
    "        fit = RandomForestClassifier(bootstrap=True,max_depth=params['max_depth'],\n",
    "                                         max_features=params['max_features'],min_samples_leaf=1,\n",
    "                                         min_samples_split=2,n_estimators=params['n_estimators'],\n",
    "                                         random_state=1).fit(X_train,y_train,sample_weight=instance_weights)\n",
    "    else:\n",
    "        raise ValueError('Invalid classification method')\n",
    "    \n",
    "    # make prediction on test set\n",
    "    predict = fit.predict(X_test)\n",
    "    \n",
    "    # calculate TPR difference\n",
    "    test_pred = test.copy()\n",
    "    test_pred.labels = predict\n",
    "    metric = ClassificationMetric(test,test_pred,unprivileged_groups=unprivileged_groups,\n",
    "                                      privileged_groups=privileged_groups)\n",
    "    tpr_diff = metric.equal_opportunity_difference()\n",
    "          \n",
    "    return tpr_diff\n",
    "\n",
    "# Find the best model i.e. the model and parameters that provide an accuracy within a user defined tolerance\n",
    "# of the best accuracy achievable from all models and parameters tested, and that provide the greatest fairness\n",
    "def FindBestModel(methods,param_dicts,X_train,y_train,train,instance_weights,unprivileged_groups,privileged_groups,\n",
    "                  X_test,y_test,test,tolerance=0.1):\n",
    "    if len(methods)!=len(param_dicts):\n",
    "        raise ValueError('Need one parameter grid per model')\n",
    "    \n",
    "    # reset seed again\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # convert shorthand strings for classification methods to models for the accuracy grid search\n",
    "    models={}\n",
    "    for method in methods:\n",
    "        if method == 'LogReg':\n",
    "            models[method] = LogisticRegression()\n",
    "        elif method == 'RForest':\n",
    "            models[method] = RandomForestClassifier()\n",
    "        else:\n",
    "            raise ValueError('Invalid classification method')\n",
    "    \n",
    "    # find the best achievable accuracy across all models and parameters\n",
    "    acc_grid_results = []\n",
    "    # best achievable accuracy for each method in a list\n",
    "    best_accs = []\n",
    "    # best achievable accuracy for all methods and parameters\n",
    "    best_acc = 0\n",
    "    for i in range(len(methods)):\n",
    "        # accuracy grid search\n",
    "        acc_score, acc_params, acc_result = GridSearchAccuracy(\n",
    "            models[methods[i]],param_dicts[i],X_train,y_train,instance_weights)\n",
    "        \n",
    "        acc_grid_results.append(acc_result)\n",
    "        best_accs.append(acc_score)\n",
    "        if acc_score > best_acc:\n",
    "            best_acc = acc_score\n",
    "    \n",
    "    # now find the best TPR difference achievable within the accuracy tolerance\n",
    "    acc = 0\n",
    "    fairness = -1\n",
    "    model = ''\n",
    "    params = {}\n",
    "    for i in range(len(methods)):\n",
    "        # don't bother checking if best accuracy for this method doesn't fall within the tolerance for current best\n",
    "        if best_accs[i] >= (1-tolerance)*best_acc:\n",
    "            # TPR grid search for best value\n",
    "            fair_score, fair_params, tpr_diff_means, param_grid_dicts = GridSearchTPR(\n",
    "                train,methods[i],unprivileged_groups,privileged_groups,param_dicts[i])\n",
    "            for j in range(len(acc_grid_results[i]['mean_test_score'])):\n",
    "                ij_acc = acc_grid_results[i]['mean_test_score'][j]\n",
    "                # check current parameters provide enough accuracy\n",
    "                if ij_acc >= (1-tolerance)*best_acc:\n",
    "                    ij_fairness = tpr_diff_means[j]\n",
    "                    # then check the fairness (TPR difference) is improved\n",
    "                    if ij_fairness > fairness:\n",
    "                        # set new best parameter values, but don't change the best achievable accuracy\n",
    "                        acc = ij_acc\n",
    "                        fairness = ij_fairness\n",
    "                        model = methods[i]\n",
    "                        params = param_grid_dicts[j]\n",
    "    \n",
    "    # now test the best parameters for accuracy and TPR difference on the test set\n",
    "    test_acc = GetAccuracy(params,X_train,y_train,X_test,y_test,test,unprivileged_groups,privileged_groups,model,\n",
    "                instance_weights)\n",
    "    test_fair = GetFairness(params,X_train,y_train,X_test,y_test,test,unprivileged_groups,privileged_groups,model,\n",
    "                instance_weights)\n",
    "    print(f\"Best model: {model} using params {params}, train accuracy: {acc}, train TPR difference {fairness}, test accuracy: {test_acc} and test TPR difference: {test_fair}\")\n",
    "    # output the best model, parameters and the accuracy and fairness on the test set\n",
    "    return (model, params, test_acc, test_fair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524ec8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    }
   ],
   "source": [
    "# Import Adult Dataset\n",
    "label_map = {1.0: '>50K', 0.0: '<=50K'}\n",
    "protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "ad = AdultDataset(protected_attribute_names=['sex'],\n",
    "                  categorical_features=['workclass', 'education', 'marital-status',\n",
    "                                        'occupation', 'relationship', 'native-country', 'race'],\n",
    "                  privileged_classes=[['Male']], \n",
    "                  metadata={'label_map': label_map, 'protected_attribute_maps': protected_attribute_maps})\n",
    "(ad_df,ad_fts) = ad.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e6cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import German Dataset\n",
    "label_map = {1.0: 'Good Credit', 0.0: 'Bad Credit'}\n",
    "protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
    "gd = GermanDataset(protected_attribute_names=['sex'],\n",
    "                   privileged_classes=[['male']], \n",
    "                   metadata={'label_map': label_map,'protected_attribute_maps': protected_attribute_maps})\n",
    "(gd_df,gd_fts) = gd.convert_to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e62ef",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4941b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size (34189, 18)\n",
      "dataset feature names ['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# Load adult dataset with binary sensitive attribute as sex\n",
    "privileged_groups_ad = [{'sex': 1}]\n",
    "unprivileged_groups_ad = [{'sex': 0}]\n",
    "ad_dataset = load_preproc_data_adult(['sex'])\n",
    "\n",
    "# Split between training and test set.\n",
    "train_ad, test_ad = ad_dataset.split([0.7], shuffle=False)\n",
    "train_ad_instance_weights = train_ad.instance_weights\n",
    "print(\"training data size\", train_ad.features.shape)\n",
    "print(\"dataset feature names\", train_ad.feature_names)\n",
    "\n",
    "# Normalize the dataset, both train and test. This should always be done in any machine learning pipeline!\n",
    "scale_orig = StandardScaler()\n",
    "X_train_ad = scale_orig.fit_transform(train_ad.features)\n",
    "y_train_ad = train_ad.labels.ravel()\n",
    "\n",
    "X_test_ad = scale_orig.transform(test_ad.features) \n",
    "y_test_ad = test_ad.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f852ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define logistic regression parameter grid dictionary\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "params_dict_lr = dict(solver=solvers,penalty=penalty,C=c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e41ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804762 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters for accuracy for logistic regression on the adult train set\n",
    "model = LogisticRegression()\n",
    "acc_score_ad, acc_params_ad, acc_result_ad = GridSearchAccuracy(model,params_dict_lr,X_train_ad,y_train_ad,\n",
    "                                                                train_ad_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8725b755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.452224 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameters for TPR difference for logistic regression on the adult train set\n",
    "fair_score_ad, fair_params_ad, tpr_diff_means_ad, param_grid_dicts_ad = GridSearchTPR(\n",
    "    train_ad,'LogReg',unprivileged_groups_ad,privileged_groups_ad,params_dict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2061bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.8023612912031666\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.8023612912031666\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.44323071830519695\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.44323071830519695\n"
     ]
    }
   ],
   "source": [
    "# test the best parameters for both methods on the on the adult test set\n",
    "acc_acc_ad, fair_acc_ad, acc_tpr_diff_ad, fair_tpr_diff_ad = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ad,fair_params_ad,X_train_ad,y_train_ad,X_test_ad,\n",
    "    y_test_ad,test_ad,unprivileged_groups_ad,privileged_groups_ad,'LogReg',train_ad_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d62e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/012314.859265:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpns8931z4/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>-0.443231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>-0.443231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  C penalty     solver  Accuracy  Fairness\n",
       "Most Accurate  0.01      l2  newton-cg  0.802361 -0.443231\n",
       "Fairest        0.01      l2  newton-cg  0.802361 -0.443231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the above results as a pandas dataframe and export png\n",
    "params_df_ad = pd.DataFrame([acc_params_ad,fair_params_ad],index=['Most Accurate','Fairest'])\n",
    "params_df_ad['Accuracy'] = [acc_acc_ad, fair_acc_ad]\n",
    "params_df_ad['Fairness'] = [acc_tpr_diff_ad, fair_tpr_diff_ad]\n",
    "dfi.export(params_df_ad, 'adult_dataframe_log_reg.png')\n",
    "params_df_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6fb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random forest parameter grid\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10,50,100,500,1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10,50,100]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# define grid search for Accuracy\n",
    "params_dict_rf = dict(n_estimators=n_estimators,max_features=max_features,max_depth=max_depth,\n",
    "               min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf,bootstrap=bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30b3285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804850 using {'bootstrap': True, 'max_depth': 100, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# accuracy grid search for random forest on the adult train dataset\n",
    "model = RandomForestClassifier()\n",
    "acc_score_ad_rf, acc_params_ad_rf, acc_result_ad_rf = GridSearchAccuracy(model,params_dict_rf,X_train_ad,y_train_ad,\n",
    "                                                                         train_ad_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd29e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.444728 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# TPR grid search for random forest on the adult train dataset\n",
    "fair_score_ad_rf, fair_params_ad_rf, tpr_diff_means_ad_rf, param_grid_dicts_ad_rf = GridSearchTPR(\n",
    "    train_ad,'RForest',unprivileged_groups_ad,privileged_groups_ad,params_dict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd881fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 100, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Accuracy 0.8009963829932437\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Accuracy 0.8004504197092746\n",
      "{'bootstrap': True, 'max_depth': 100, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.4468718967229394\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.4276729559748428\n"
     ]
    }
   ],
   "source": [
    "# now test the above parameters on the test set\n",
    "acc_acc_ad_rf, fair_acc_ad_rf, acc_tpr_diff_ad_rf, fair_tpr_diff_ad_rf = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ad_rf,fair_params_ad_rf,X_train_ad,y_train_ad,X_test_ad,y_test_ad,\n",
    "    test_ad,unprivileged_groups_ad,privileged_groups_ad,'RForest',train_ad_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539b3e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/013128.860842:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpm9l7vc37/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.800996</td>\n",
       "      <td>-0.446872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.800450</td>\n",
       "      <td>-0.427673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bootstrap  max_depth max_features  min_samples_leaf  \\\n",
       "Most Accurate       True        100         auto                 1   \n",
       "Fairest             True         10         auto                 1   \n",
       "\n",
       "               min_samples_split  n_estimators  Accuracy  Fairness  \n",
       "Most Accurate                  2            10  0.800996 -0.446872  \n",
       "Fairest                        2            10  0.800450 -0.427673  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again, pandas dataframe and png output\n",
    "params_df_ad_rf = pd.DataFrame([acc_params_ad_rf,fair_params_ad_rf],index=['Most Accurate','Fairest'])\n",
    "params_df_ad_rf['Accuracy'] = [acc_acc_ad_rf, fair_acc_ad_rf]\n",
    "params_df_ad_rf['Fairness'] = [acc_tpr_diff_ad_rf, fair_tpr_diff_ad_rf]\n",
    "dfi.export(params_df_ad_rf, 'adult_dataframe_random_forest.png')\n",
    "params_df_ad_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ef0e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size (700, 11)\n",
      "dataset feature names ['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# Load German dataset with binary sensitive attribute as sex\n",
    "privileged_groups_ge = [{'sex': 1}]\n",
    "unprivileged_groups_ge = [{'sex': 0}]\n",
    "ge_dataset = load_preproc_data_german(['sex'])\n",
    "\n",
    "# Split between training and test set.\n",
    "train_ge, test_ge = ge_dataset.split([0.7], shuffle=False)\n",
    "train_ge_instance_weights = train_ge.instance_weights\n",
    "print(\"training data size\", train_ge.features.shape)\n",
    "print(\"dataset feature names\", train_ge.feature_names)\n",
    "\n",
    "# Normalize the dataset, both train and test. This should always be done in any machine learning pipeline!\n",
    "scale_orig = StandardScaler()\n",
    "X_train_ge = scale_orig.fit_transform(train_ge.features)\n",
    "y_train_ge = train_ge.labels.ravel()\n",
    "\n",
    "X_test_ge = scale_orig.transform(test_ge.features) \n",
    "y_test_ge = test_ge.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7e429b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.705714 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.012121 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# grid search for both metrics for logistic regression on the german dataset\n",
    "model = LogisticRegression()\n",
    "acc_score_ge, acc_params_ge, acc_result_ge = GridSearchAccuracy(model,params_dict_lr,X_train_ge,y_train_ge,\n",
    "                                                                train_ge_instance_weights)\n",
    "\n",
    "print(\"\")\n",
    "fair_score_ge, fair_params_ge, tpr_diff_means_ge, param_grid_dicts_ge = GridSearchTPR(\n",
    "    train_ge,'LogReg',unprivileged_groups_ge,privileged_groups_ge,params_dict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b69de75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.697143 using {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.104215 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# grid search for both metrics for random forest on the german dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "acc_score_ge_rf, acc_params_ge_rf, acc_result_ge_rf = GridSearchAccuracy(model,params_dict_rf,X_train_ge,y_train_ge,\n",
    "                                                                         train_ge_instance_weights)\n",
    "    \n",
    "print(\"\")\n",
    "fair_score_ge_rf, fair_params_ge_rf, tpr_diff_means_ge_rf, param_grid_dicts_ge_rf = GridSearchTPR(\n",
    "    train_ge,'RForest',unprivileged_groups_ge,privileged_groups_ge,params_dict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ac5dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.6866666666666666\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.6866666666666666\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.01666666666666672\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.01666666666666672\n",
      "\n",
      "Random Forest\n",
      "{'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000} Accuracy 0.7\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500} Accuracy 0.7\n",
      "{'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.13265306122448972\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.13265306122448972\n"
     ]
    }
   ],
   "source": [
    "# test the most accurate and fairest logistic regression parameters on the german dataset\n",
    "print(\"Logistic Regression\")\n",
    "acc_acc_ge, fair_acc_ge, acc_tpr_diff_ge, fair_tpr_diff_ge = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ge,fair_params_ge,X_train_ge,y_train_ge,X_test_ge,y_test_ge,test_ge,\n",
    "    unprivileged_groups_ge,privileged_groups_ge,'LogReg',train_ge_instance_weights)\n",
    "\n",
    "# test the most accurate and fairest random forest parameters on the german dataset\n",
    "print(\"\")\n",
    "print(\"Random Forest\")\n",
    "acc_acc_ge_rf, fair_acc_ge_rf, acc_tpr_diff_ge_rf, fair_tpr_diff_ge_rf = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ge_rf,fair_params_ge_rf,X_train_ge,y_train_ge,X_test_ge,y_test_ge,\n",
    "    test_ge,unprivileged_groups_ge,privileged_groups_ge,'RForest',train_ge_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d149fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/013239.416284:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpr11q54mc/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>-0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>-0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  C penalty     solver  Accuracy  Fairness\n",
       "Most Accurate  0.01      l2  newton-cg  0.686667 -0.016667\n",
       "Fairest        0.01      l2  newton-cg  0.686667 -0.016667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output logistic regression test results for german dataset as png\n",
    "params_df_ge = pd.DataFrame([acc_params_ge,fair_params_ge],index=['Most Accurate','Fairest'])\n",
    "params_df_ge['Accuracy'] = [acc_acc_ge, fair_acc_ge]\n",
    "params_df_ge['Fairness'] = [acc_tpr_diff_ge, fair_tpr_diff_ge]\n",
    "dfi.export(params_df_ge, 'german_dataframe_log_reg.png')\n",
    "params_df_ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5fd7f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/013241.248695:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpriklojnr/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.132653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.132653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bootstrap  max_depth max_features  min_samples_leaf  \\\n",
       "Most Accurate       True        NaN         log2                 1   \n",
       "Fairest             True       10.0         auto                 1   \n",
       "\n",
       "               min_samples_split  n_estimators  Accuracy  Fairness  \n",
       "Most Accurate                  2          1000       0.7 -0.132653  \n",
       "Fairest                        2           500       0.7 -0.132653  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output random forest test results for german dataset as png\n",
    "params_df_ge_rf = pd.DataFrame([acc_params_ge_rf,fair_params_ge_rf],index=['Most Accurate','Fairest'])\n",
    "params_df_ge_rf['Accuracy'] = [acc_acc_ge_rf, fair_acc_ge_rf]\n",
    "params_df_ge_rf['Fairness'] = [acc_tpr_diff_ge_rf, fair_tpr_diff_ge_rf]\n",
    "dfi.export(params_df_ge_rf, 'german_dataframe_random_forest.png')\n",
    "params_df_ge_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec16eb3",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f29baec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size (34189, 18)\n",
      "dataset feature names ['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# REWEIGH ON ADULT\n",
    "# Reweight adult dataset\n",
    "ad_dataset_rw = Reweighing(unprivileged_groups=unprivileged_groups_ad,\n",
    "                           privileged_groups=privileged_groups_ad).fit_transform(ad_dataset)\n",
    "\n",
    "# Split between training and test set.\n",
    "train_ad_rw, test_ad_rw = ad_dataset_rw.split([0.7], shuffle=False)\n",
    "train_ad_rw_instance_weights = train_ad_rw.instance_weights\n",
    "print(\"training data size\", train_ad_rw.features.shape)\n",
    "print(\"dataset feature names\", train_ad_rw.feature_names)\n",
    "\n",
    "# Normalize the dataset, both train and test. This should always be done in any machine learning pipeline!\n",
    "scale_orig = StandardScaler()\n",
    "X_train_ad_rw = scale_orig.fit_transform(train_ad_rw.features)\n",
    "y_train_ad_rw = train_ad_rw.labels.ravel()\n",
    "\n",
    "X_test_ad_rw = scale_orig.transform(test_ad_rw.features) \n",
    "y_test_ad_rw = test_ad_rw.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62832242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804762 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# reweighted logistic regression accuracy grid search on adult set\n",
    "model = LogisticRegression()\n",
    "acc_score_ad_rw, acc_params_ad_rw, acc_result_ad_rw = GridSearchAccuracy(model,params_dict_lr,X_train_ad_rw,y_train_ad_rw,\n",
    "                                                                         train_ad_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18b8ce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.011044 using {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# reweighted logistic regression fairness grid search on adult set\n",
    "fair_score_ad_rw, fair_params_ad_rw, tpr_diff_means_ad_rw, param_grid_dicts_ad_rw = GridSearchTPR(\n",
    "    train_ad_rw,'LogReg',unprivileged_groups_ad,privileged_groups_ad,params_dict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd9b5b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.7865966013785572\n",
      "{'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.7865966013785572\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.03669471982898115\n",
      "{'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference 0.004273622815339162\n"
     ]
    }
   ],
   "source": [
    "# testing the best logistic regression parameters on the reweighted adult set\n",
    "acc_acc_ad_rw, fair_acc_ad_rw, acc_tpr_diff_ad_rw, fair_tpr_diff_ad_rw = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ad_rw,fair_params_ad_rw,X_train_ad_rw,y_train_ad_rw,X_test_ad_rw,\n",
    "    y_test_ad_rw,test_ad_rw,unprivileged_groups_ad,privileged_groups_ad,'LogReg',train_ad_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13ab336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/013251.860568:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpf6lfg5fj/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>-0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>100.00</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    C penalty     solver  Accuracy  Fairness\n",
       "Most Accurate    0.01      l2  newton-cg  0.786597 -0.036695\n",
       "Fairest        100.00      l2  newton-cg  0.786597  0.004274"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# png output for above results\n",
    "params_df_ad_rw = pd.DataFrame([acc_params_ad_rw,fair_params_ad_rw],index=['Most Accurate','Fairest'])\n",
    "params_df_ad_rw['Accuracy'] = [acc_acc_ad_rw, fair_acc_ad_rw]\n",
    "params_df_ad_rw['Fairness'] = [acc_tpr_diff_ad_rw, fair_tpr_diff_ad_rw]\n",
    "dfi.export(params_df_ad_rw, 'adult_dataframe_log_reg_reweigh.png')\n",
    "params_df_ad_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5b30126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804703 using {'bootstrap': True, 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# reweighted random forest accuracy grid search on adult set\n",
    "model = RandomForestClassifier()\n",
    "acc_score_ad_rf_rw, acc_params_ad_rf_rw, acc_result_ad_rf_rw = GridSearchAccuracy(model,params_dict_rf,X_train_ad_rw,\n",
    "                                                                                  y_train_ad_rw,\n",
    "                                                                                  train_ad_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "010877a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.101872 using {'bootstrap': True, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# reweighted random forest tpr difference grid search on adult set\n",
    "fair_score_ad_rf_rw, fair_params_ad_rf_rw, tpr_diff_means_ad_rf_rw, param_grid_dicts_ad_rf_rw = GridSearchTPR(\n",
    "    train_ad_rw,'RForest',unprivileged_groups_ad,privileged_groups_ad,params_dict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec017995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Accuracy 0.7747218999522282\n",
      "{'bootstrap': True, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Accuracy 0.7747218999522282\n",
      "{'bootstrap': True, 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference 0.10427935549847533\n",
      "{'bootstrap': True, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference 0.10427935549847533\n"
     ]
    }
   ],
   "source": [
    "# test above parameters on reweighted adult test set\n",
    "acc_acc_ad_rf_rw, fair_acc_ad_rf_rw, acc_tpr_diff_ad_rf_rw, fair_tpr_diff_ad_rf_rw = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ad_rf_rw,fair_params_ad_rf_rw,X_train_ad_rw,y_train_ad_rw,X_test_ad_rw,\n",
    "    y_test_ad_rw,test_ad_rw,unprivileged_groups_ad,privileged_groups_ad,'RForest',train_ad_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51a9aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/014108.625882:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmp6q042p8s/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.774722</td>\n",
       "      <td>0.104279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.774722</td>\n",
       "      <td>0.104279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bootstrap  max_depth max_features  min_samples_leaf  \\\n",
       "Most Accurate       True         50         log2                 1   \n",
       "Fairest             True         50         auto                 1   \n",
       "\n",
       "               min_samples_split  n_estimators  Accuracy  Fairness  \n",
       "Most Accurate                  2            10  0.774722  0.104279  \n",
       "Fairest                        2            10  0.774722  0.104279  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output above results as png\n",
    "params_df_ad_rf_rw = pd.DataFrame([acc_params_ad_rf_rw,fair_params_ad_rf_rw],index=['Most Accurate','Fairest'])\n",
    "params_df_ad_rf_rw['Accuracy'] = [acc_acc_ad_rf_rw, fair_acc_ad_rf_rw]\n",
    "params_df_ad_rf_rw['Fairness'] = [acc_tpr_diff_ad_rf_rw, fair_tpr_diff_ad_rf_rw]\n",
    "dfi.export(params_df_ad_rf_rw, 'adult_dataframe_random_forest_reweigh.png')\n",
    "params_df_ad_rf_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baacb65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size (700, 11)\n",
      "dataset feature names ['age', 'sex', 'credit_history=Delay', 'credit_history=None/Paid', 'credit_history=Other', 'savings=500+', 'savings=<500', 'savings=Unknown/None', 'employment=1-4 years', 'employment=4+ years', 'employment=Unemployed']\n"
     ]
    }
   ],
   "source": [
    "# REWEIGH ON GERMAN\n",
    "# Reweight German dataset\n",
    "ge_dataset_rw = Reweighing(unprivileged_groups=unprivileged_groups_ge,\n",
    "                           privileged_groups=privileged_groups_ge).fit_transform(ge_dataset)\n",
    "\n",
    "# Split between training and test set.\n",
    "train_ge_rw, test_ge_rw = ge_dataset_rw.split([0.7], shuffle=False)\n",
    "train_ge_rw_instance_weights = train_ge_rw.instance_weights\n",
    "print(\"training data size\", train_ge_rw.features.shape)\n",
    "print(\"dataset feature names\", train_ge_rw.feature_names)\n",
    "\n",
    "# Normalize the dataset, both train and test. This should always be done in any machine learning pipeline!\n",
    "scale_orig = StandardScaler()\n",
    "X_train_ge_rw = scale_orig.fit_transform(train_ge_rw.features)\n",
    "y_train_ge_rw = train_ge_rw.labels.ravel()\n",
    "\n",
    "X_test_ge_rw = scale_orig.transform(test_ge_rw.features) \n",
    "y_test_ge_rw = test_ge_rw.labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4db9327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.705714 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# reweighted logistic regression accuracy grid search on German set\n",
    "model = LogisticRegression()\n",
    "acc_score_ge_rw, acc_params_ge_rw, acc_result_ge_rw = GridSearchAccuracy(model,params_dict_lr,X_train_ge_rw,y_train_ge_rw,\n",
    "                                                                         train_ge_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9606dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.017537 using {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# reweighted logistic regression fairness grid search on German set\n",
    "fair_score_ge_rw, fair_params_ge_rw, tpr_diff_means_ge_rw, param_grid_dicts_ge_rw = GridSearchTPR(\n",
    "    train_ge_rw,'LogReg',unprivileged_groups_ge,privileged_groups_ge,params_dict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37de3b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Accuracy 0.69\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'} Accuracy 0.68\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference 0.0\n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.02278911564625885\n"
     ]
    }
   ],
   "source": [
    "# test above parameters on reweighted test set\n",
    "acc_acc_ge_rw, fair_acc_ge_rw, acc_tpr_diff_ge_rw, fair_tpr_diff_ge_rw = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ge_rw,fair_params_ge_rw,X_train_ge_rw,y_train_ge_rw,X_test_ge_rw,y_test_ge_rw,test_ge_rw,\n",
    "    unprivileged_groups_ge,privileged_groups_ge,'LogReg',train_ge_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "041c5747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/014112.802604:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpnjt9s4cj/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.022789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  C penalty     solver  Accuracy  Fairness\n",
       "Most Accurate  0.01      l2  newton-cg      0.69  0.000000\n",
       "Fairest        0.01      l2  liblinear      0.68 -0.022789"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# png output of above results\n",
    "params_df_ge_rw = pd.DataFrame([acc_params_ge_rw,fair_params_ge_rw],index=['Most Accurate','Fairest'])\n",
    "params_df_ge_rw['Accuracy'] = [acc_acc_ge_rw, fair_acc_ge_rw]\n",
    "params_df_ge_rw['Fairness'] = [acc_tpr_diff_ge_rw, fair_tpr_diff_ge_rw]\n",
    "dfi.export(params_df_ge_rw, 'german_dataframe_log_reg_reweigh.png')\n",
    "params_df_ge_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8efe7312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.700000 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# reweighted random forest accuracy grid search on German set\n",
    "model = RandomForestClassifier()\n",
    "acc_score_ge_rf_rw, acc_params_ge_rf_rw, acc_result_ge_rf_rw = GridSearchAccuracy(model,params_dict_rf,X_train_ge_rw,\n",
    "                                                                                  y_train_ge_rw,\n",
    "                                                                                  train_ge_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93af4eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.080178 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# reweighted random forest fairness grid search on German set\n",
    "fair_score_ge_rf_rw, fair_params_ge_rf_rw, tpr_diff_means_ge_rf_rw, param_grid_dicts_ge_rf_rw = GridSearchTPR(\n",
    "    train_ge_rw,'RForest',unprivileged_groups_ge,privileged_groups_ge,params_dict_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7d10754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Accuracy 0.7033333333333334\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500} Accuracy 0.7\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.13945578231292544\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500} Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference -0.13265306122448972\n"
     ]
    }
   ],
   "source": [
    "# test above parameters on test set\n",
    "acc_acc_ge_rf_rw, fair_acc_ge_rf_rw, acc_tpr_diff_ge_rf_rw, fair_tpr_diff_ge_rf_rw = GetAccAndFairnessForBestParams(\n",
    "    acc_params_ge_rf_rw,fair_params_ge_rf_rw,X_train_ge_rw,y_train_ge_rw,X_test_ge_rw,y_test_ge_rw,test_ge_rw,\n",
    "    unprivileged_groups_ge,privileged_groups_ge,'RForest',train_ge_rw_instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ee02446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/014219.325299:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpa0lce3fk/temp.png.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Fairness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Accurate</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>-0.139456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairest</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.132653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bootstrap  max_depth max_features  min_samples_leaf  \\\n",
       "Most Accurate       True         10         log2                 1   \n",
       "Fairest             True         10         auto                 1   \n",
       "\n",
       "               min_samples_split  n_estimators  Accuracy  Fairness  \n",
       "Most Accurate                  2            10  0.703333 -0.139456  \n",
       "Fairest                        2           500  0.700000 -0.132653  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# png output of above results\n",
    "params_df_ge_rf_rw = pd.DataFrame([acc_params_ge_rf_rw,fair_params_ge_rf_rw],index=['Most Accurate','Fairest'])\n",
    "params_df_ge_rf_rw['Accuracy'] = [acc_acc_ge_rf_rw, fair_acc_ge_rf_rw]\n",
    "params_df_ge_rf_rw['Fairness'] = [acc_tpr_diff_ge_rf_rw, fair_tpr_diff_ge_rf_rw]\n",
    "dfi.export(params_df_ge_rf_rw, 'german_dataframe_random_forest_reweigh.png')\n",
    "params_df_ge_rf_rw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8935b3f",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc61b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all methods and parameters to try\n",
    "methods = ['LogReg', 'RForest']\n",
    "grids = [params_dict_lr, params_dict_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5c98fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804762 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.804791 using {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.452224 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.444728 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best model: RForest using params {'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': True}, train accuracy: 0.8040307194183637, train TPR difference -0.44472832020787145, test accuracy: 0.8004504197092746 and test TPR difference: -0.4276729559748428\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the adult dataset with default tolerance (10%)\n",
    "best_model_ad1, best_params_ad1, best_acc_ad1, best_fairness_ad1 = FindBestModel(\n",
    "    methods,grids,X_train_ad,y_train_ad,train_ad,train_ad_instance_weights,unprivileged_groups_ad,\n",
    "    privileged_groups_ad,X_test_ad,y_test_ad,test_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1db06674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804762 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.804674 using {'bootstrap': True, 'max_depth': 50, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.452224 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best model: LogReg using params {'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.01}, train accuracy: 0.8047619273739061, train TPR difference -0.4522235201576622, test accuracy: 0.8023612912031666 and test TPR difference: -0.44323071830519695\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the adult dataset with 0.01% tolerance\n",
    "best_model_ad2, best_params_ad2, best_acc_ad2, best_fairness_ad2 = FindBestModel(\n",
    "    methods,grids,X_train_ad,y_train_ad,train_ad,train_ad_instance_weights,unprivileged_groups_ad,\n",
    "    privileged_groups_ad,X_test_ad,y_test_ad,test_ad,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd29bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804762 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.804762 using {'bootstrap': True, 'max_depth': 100, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.011044 using {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.101872 using {'bootstrap': True, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best model: RForest using params {'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': True}, train accuracy: 0.8044694441916892, train TPR difference 0.10187193301989055, test accuracy: 0.7747218999522282 and test TPR difference: 0.10427935549847533\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the reweighted adult dataset with default tolerance (10%)\n",
    "best_model_ad_rw1, best_params_ad_rw1, best_acc_ad_rw1, best_fairness_ad_rw1 = FindBestModel(\n",
    "    methods,grids,X_train_ad_rw,y_train_ad_rw,train_ad_rw,train_ad_rw_instance_weights,\n",
    "    unprivileged_groups_ad,privileged_groups_ad,X_test_ad_rw,y_test_ad_rw,test_ad_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbd4da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.804762 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.804674 using {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.011044 using {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best model: LogReg using params {'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.01}, train accuracy: 0.8047619273739061, train TPR difference 0.007152498955769327, test accuracy: 0.7865966013785572 and test TPR difference: -0.03669471982898115\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the reweighted adult dataset with 0.1% tolerance\n",
    "best_model_ad_rw2, best_params_ad_rw2, best_acc_ad_rw2, best_fairness_ad_rw2 = FindBestModel(\n",
    "    methods,grids,X_train_ad_rw,y_train_ad_rw,train_ad_rw,train_ad_rw_instance_weights,\n",
    "    unprivileged_groups_ad,privileged_groups_ad,X_test_ad_rw,y_test_ad_rw,test_ad_rw,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c0b5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.705714 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.701429 using {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.012121 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.104215 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best model: LogReg using params {'solver': 'newton-cg', 'penalty': 'l2', 'C': 0.01}, train accuracy: 0.7057142857142856, train TPR difference -0.01212121212121211, test accuracy: 0.6866666666666666 and test TPR difference: -0.01666666666666672\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the german dataset with default tolerance (10%)\n",
    "best_model_ge, best_params_ge, best_acc_ge, best_fairness_ge = FindBestModel(\n",
    "    methods,grids,X_train_ge,y_train_ge,train_ge,train_ge_instance_weights,unprivileged_groups_ge,\n",
    "    privileged_groups_ge,X_test_ge,y_test_ge,test_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbec9392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.705714 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.702857 using {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.017537 using {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.080178 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best model: LogReg using params {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.01}, train accuracy: 0.687142857142857, train TPR difference 0.017536551930144785, test accuracy: 0.68 and test TPR difference: -0.02278911564625885\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the reweighted german dataset with default tolerance (10%)\n",
    "best_model_ge_rw1, best_params_ge_rw1, best_acc_ge_rw1, best_fairness_ge_rw1 = FindBestModel(\n",
    "    methods,grids,X_train_ge_rw,y_train_ge_rw,train_ge_rw,train_ge_rw_instance_weights,\n",
    "    unprivileged_groups_ge,privileged_groups_ge,X_test_ge_rw,y_test_ge_rw,test_ge_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b7fed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Best: 0.705714 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy\n",
      "Best: 0.704286 using {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: 0.017537 using {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Fairness metric of equality of opportunity, i.e. true positive rate (TPR) difference\n",
      "Best: -0.080178 using {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best model: LogReg using params {'solver': 'newton-cg', 'penalty': 'l2', 'C': 100}, train accuracy: 0.7000000000000001, train TPR difference 0.010356051271383237, test accuracy: 0.68 and test TPR difference: -0.02278911564625885\n"
     ]
    }
   ],
   "source": [
    "# find best criterion model and parameters for the reweighted german dataset with 1% tolerance\n",
    "best_model_ge_rw2, best_params_ge_rw2, best_acc_ge_rw2, best_fairness_ge_rw2 = FindBestModel(\n",
    "    methods,grids,X_train_ge_rw,y_train_ge_rw,train_ge_rw,train_ge_rw_instance_weights,\n",
    "    unprivileged_groups_ge,privileged_groups_ge,X_test_ge_rw,y_test_ge_rw,test_ge_rw,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6ceaeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>solver</th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>TPR difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adult 0.1 Tolerance</th>\n",
       "      <td>RForest</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.800450</td>\n",
       "      <td>-0.427673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult 0.001 Tolerance</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>-0.443231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighted Adult 0.1 Tolerance</th>\n",
       "      <td>RForest</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.774722</td>\n",
       "      <td>0.104279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighted Adult 0.001 Tolerance</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.786597</td>\n",
       "      <td>-0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German 0.1 Tolerance</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>-0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighted German 0.1 Tolerance</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>-0.022789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reweighted German 0.01 Tolerance</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>-0.022789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model     solver penalty     C  \\\n",
       "Adult 0.1 Tolerance               RForest        N/A     N/A   N/A   \n",
       "Adult 0.001 Tolerance              LogReg  newton-cg      l2  0.01   \n",
       "Reweighted Adult 0.1 Tolerance    RForest        N/A     N/A   N/A   \n",
       "Reweighted Adult 0.001 Tolerance   LogReg  newton-cg      l2  0.01   \n",
       "German 0.1 Tolerance               LogReg  newton-cg      l2  0.01   \n",
       "Reweighted German 0.1 Tolerance    LogReg  liblinear      l2  0.01   \n",
       "Reweighted German 0.01 Tolerance   LogReg  newton-cg      l2   100   \n",
       "\n",
       "                                 n_estimators max_features max_depth  \\\n",
       "Adult 0.1 Tolerance                        10         auto        10   \n",
       "Adult 0.001 Tolerance                     N/A          N/A       N/A   \n",
       "Reweighted Adult 0.1 Tolerance             10         auto        50   \n",
       "Reweighted Adult 0.001 Tolerance          N/A          N/A       N/A   \n",
       "German 0.1 Tolerance                      N/A          N/A       N/A   \n",
       "Reweighted German 0.1 Tolerance           N/A          N/A       N/A   \n",
       "Reweighted German 0.01 Tolerance          N/A          N/A       N/A   \n",
       "\n",
       "                                 min_samples_split min_samples_leaf bootstrap  \\\n",
       "Adult 0.1 Tolerance                              2                1      True   \n",
       "Adult 0.001 Tolerance                          N/A              N/A       N/A   \n",
       "Reweighted Adult 0.1 Tolerance                   2                1      True   \n",
       "Reweighted Adult 0.001 Tolerance               N/A              N/A       N/A   \n",
       "German 0.1 Tolerance                           N/A              N/A       N/A   \n",
       "Reweighted German 0.1 Tolerance                N/A              N/A       N/A   \n",
       "Reweighted German 0.01 Tolerance               N/A              N/A       N/A   \n",
       "\n",
       "                                  accuracy  TPR difference  \n",
       "Adult 0.1 Tolerance               0.800450       -0.427673  \n",
       "Adult 0.001 Tolerance             0.802361       -0.443231  \n",
       "Reweighted Adult 0.1 Tolerance    0.774722        0.104279  \n",
       "Reweighted Adult 0.001 Tolerance  0.786597       -0.036695  \n",
       "German 0.1 Tolerance              0.686667       -0.016667  \n",
       "Reweighted German 0.1 Tolerance   0.680000       -0.022789  \n",
       "Reweighted German 0.01 Tolerance  0.680000       -0.022789  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code cell outputs all of the best model parameters and corresponding metrics as a pandas dataframe\n",
    "best_model_list = [best_model_ad1, best_model_ad2, best_model_ad_rw1, best_model_ad_rw2, \n",
    "                   best_model_ge, best_model_ge_rw1, best_model_ge_rw2]\n",
    "best_params_list_of_dicts = [best_params_ad1, best_params_ad2, best_params_ad_rw1, best_params_ad_rw2, \n",
    "                             best_params_ge, best_params_ge_rw1, best_params_ge_rw2]\n",
    "best_params_dict_of_lists = {}\n",
    "all_params = []\n",
    "for i in params_dict_lr.keys():\n",
    "    all_params.append(i)\n",
    "for i in params_dict_rf.keys():\n",
    "    all_params.append(i)\n",
    "for i in all_params:\n",
    "    best_params_dict_of_lists[i] = []\n",
    "    for j in best_params_list_of_dicts:\n",
    "        best_params_dict_of_lists[i].append(j.get(i,'N/A'))\n",
    "best_acc_list = [best_acc_ad1, best_acc_ad2, best_acc_ad_rw1, best_acc_ad_rw2, \n",
    "                 best_acc_ge, best_acc_ge_rw1, best_acc_ge_rw2]\n",
    "best_fairness_list = [best_fairness_ad1, best_fairness_ad2, best_fairness_ad_rw1, best_fairness_ad_rw2, \n",
    "                      best_fairness_ge, best_fairness_ge_rw1, best_fairness_ge_rw2]\n",
    "best_dict = {}\n",
    "best_dict.update({'model': best_model_list})\n",
    "best_dict.update(best_params_dict_of_lists)\n",
    "best_dict.update({'accuracy': best_acc_list})\n",
    "best_dict.update({'TPR difference': best_fairness_list})\n",
    "best_df = pd.DataFrame(\n",
    "    best_dict, index = ['Adult 0.1 Tolerance', 'Adult 0.001 Tolerance', 'Reweighted Adult 0.1 Tolerance',\n",
    "                        'Reweighted Adult 0.001 Tolerance', 'German 0.1 Tolerance', \n",
    "                        'Reweighted German 0.1 Tolerance', 'Reweighted German 0.01 Tolerance'])\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9dcd4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0518/123344.507223:INFO:headless_shell.cc(660)] Written to file /var/folders/n7/079skxw56td31dml628vdw9h0000gn/T/tmpbqaeqpu9/temp.png.\n"
     ]
    }
   ],
   "source": [
    "# this exports the above dataframe as a png\n",
    "dfi.export(best_df, 'best_df.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb50ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
